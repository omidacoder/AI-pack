# -*- coding: utf-8 -*-
"""OmidDavarTransferlearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ETw9j5xC9r2ZY6xKILIXpR4tQ2VAeUZ5
"""

!nvidia-smi

# import things
import tensorflow as tf
from google.colab import drive
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from sklearn.utils import shuffle
from keras.applications.vgg16 import VGG16

# reading dataset files
import time
from tqdm import tqdm
# unpacking data
from zipfile import ZipFile
with ZipFile("drive/My Drive/mnist/Medical MNIST.zip","r") as zip_ref:
     for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):
          zip_ref.extract(member=file,path="mnist")
# put dataset path in below variable
directory = "./mnist"
# # Medical Mnist Image size is 64 * 64
data = tf.keras.preprocessing.image_dataset_from_directory(
    directory, color_mode='rgb', batch_size=32, image_size=(64, 64), shuffle=True
)
# # reading vgg16 model
model = VGG16(weights='imagenet' , include_top=False , input_shape=(64,64,3))
# # freezing layers to add new layers later
for layer in model.layers:
  layer.trainable = False

# changing model
output = model.output
layer = tf.keras.layers.Flatten()(output)
layer = tf.keras.layers.Dense(units=2048)(layer)
layer = tf.keras.layers.Dropout(0.05)(layer) # avoid overfitting
layer = tf.keras.layers.Dense(units=2048)(layer)
layer = tf.keras.layers.Dense(units=6 , activation='softmax')(layer)
model = tf.keras.Model(
        inputs=model.input,
        outputs=layer,
    )
# compiling model
# sparse categorical loss function means labels are integers but output is 6 length tensor
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , optimizer="Adam" , metrics = ["accuracy"])
print(model.summary())

# train model using new data
train = data.take(int(len(data)*70/100))
test = data.skip(int(len(data)*70/100)).take(int(len(data)*30/100))
model.fit(train , epochs=1 ,batch_size=32)

model.evaluate(test)